{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from os import path\n",
    "import time \n",
    "from datetime import datetime \n",
    "import math\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import cv2\n",
    "import mimetypes\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = path.join('..', 'data')\n",
    "img_dir = path.join(data_dir, 'img')\n",
    "temp_dir = path.join(data_dir, 'temp')\n",
    "\n",
    "dataset_file = 'reddit_wsb_art.csv'\n",
    "\n",
    "data = pd.read_csv(path.join(data_dir, dataset_file))\n",
    "data = data.sort_values(by=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_HTTP = re.compile(\"http(s)?://[/\\.A-z0-9]+\")\n",
    "\n",
    "def detect_urls(text):\n",
    "    text = str(text)\n",
    "\n",
    "    return [str(x[1].group(0)) for x in enumerate(re.finditer(RE_HTTP, text))]\n",
    "\n",
    "data['body_url'] = data.apply(lambda x: detect_urls(x['body']), axis=1) \n",
    "data['body_urls_count'] = data['body_url'].apply(len)\n",
    "\n",
    "data[['body', 'body_url', 'body_urls_count']].loc[data['body_urls_count'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_url_image(url):    \n",
    "    mimetype,encoding = mimetypes.guess_type(url)\n",
    "    return (mimetype and mimetype.startswith('image'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, name):\n",
    "    try:\n",
    "        request = requests.get(url, stream = True)\n",
    "        status = request.status_code\n",
    "    except:\n",
    "#         print('Connection error: ', url)\n",
    "        status = -1\n",
    "    \n",
    "    if status == 200:\n",
    "        with open(path.join(temp_dir, name), 'wb') as file:\n",
    "            file.write(request.content)\n",
    "#             print('Image sucessfully Downloaded: ', name, ' From: ', url)\n",
    "            return True\n",
    "    else:\n",
    "#         print(\"Image Couldn't be retreived\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(url):\n",
    "    return url.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_reddit_preview_url(url):\n",
    "    return url.replace('preview.redd.it', 'i.redd.it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19  import VGG19, preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.applications.vgg19  import VGG19, preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "from skimage.color import rgb2hsv\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "def get_img_avg_colors(image_path):\n",
    "    image = load_img(image_path)\n",
    "    image = img_to_array(image)\n",
    "    \n",
    "#     image = image / 255.0\n",
    "    \n",
    "    X = 0.0\n",
    "    Y = 0.0\n",
    "\n",
    "    count = 0\n",
    "    sat = 0\n",
    "    val = 0\n",
    "    \n",
    "    hsv = rgb2hsv(image)\n",
    "\n",
    "    for i in range(0,image.shape[0], 128):\n",
    "        for j in range(0,image.shape[1], 128):\n",
    "            X += math.cos(hsv[i,j,0] / 180.0 * math.pi)\n",
    "            Y += math.sin(hsv[i,j,0] / 180.0 * math.pi)\n",
    "            sat += hsv[i,j,1]\n",
    "            val += hsv[i,j,2]\n",
    "            count += 1\n",
    "\n",
    "    #Now average the X and Y values\n",
    "    X /= count\n",
    "    Y /= count\n",
    "\n",
    "    avg_hue = math.atan2(Y, X) * 180.0 / math.pi;\n",
    "    avg_sat = sat / count\n",
    "    avg_val = val / count\n",
    "\n",
    "    return avg_hue, avg_sat, avg_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19  import VGG19, preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "model = VGG19()\n",
    "\n",
    "def get_img_label(image_path):\n",
    "    image = load_img(image_path, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "    yhat  = model.predict(image)\n",
    "    label = decode_predictions(yhat, top=5)\n",
    "    label = label[0][0]\n",
    "#     print('%s (%.2f%%)' % (label[1], label[2]*100))\n",
    "    return label[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_urls(url_list):\n",
    "\n",
    "    labels = []\n",
    "    colors = []\n",
    "    colors_stdevs = []\n",
    "    \n",
    "    for url in url_list:\n",
    "        if is_url_image(url):\n",
    "            name = get_name(url)\n",
    "            url = correct_reddit_preview_url(url)\n",
    "            \n",
    "            file_exists = False\n",
    "            path_to_file = os.path.join(temp_dir, name)\n",
    "            if os.path.exists(path_to_file):\n",
    "                file_exists = True\n",
    "            else:\n",
    "                download_successful = download_image(url, name)\n",
    "                file_exists = download_successful\n",
    "\n",
    "#             print(path_to_file)\n",
    "            if file_exists:\n",
    "#                 label = 'nothing'\n",
    "                label = get_img_label(path_to_file)\n",
    "                labels.append(label)\n",
    "                \n",
    "#                 avg_col = 0,0,0\n",
    "                avg_col = get_img_avg_colors(path_to_file)\n",
    "                colors.append(avg_col)\n",
    "                \n",
    "#     print(colors, colors_stdevs)\n",
    "    return labels, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp = data['body_url'].apply(lambda x: process_urls(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['imgs_labels'] = temp.apply(lambda x: x[0])\n",
    "data['imgs_colors'] = temp.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['imgs_colors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['imgs_count'] = data['imgs_labels'].apply(lambda x: len(x) if x == [] else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['body_url', 'body_urls_count', 'imgs_colors','imgs_count']].loc[data['imgs_count'].gt(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['body_url', 'body_urls_count','imgs_count']].loc[data['imgs_count'].gt(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['body_url', 'body_urls_count', 'imgs_labels','imgs_count']].loc[data['imgs_count'].gt(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(np.concatenate(data.imgs_labels.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[['body_url', 'body_urls_count', 'imgs_labels','imgs_count']].loc[data['imgs_count'].gt(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python37664bitanaconda3virtualenv479a4a6d335c4a66b4edef7caa9238ba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
